{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import library\n",
    "from math import exp\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "\n",
    "\n",
    "import import_ipynb\n",
    "from  logisticregression import (logistic_regression, predictedoutcome)\n",
    "from knnalgorithm import (k_nearest_neighbors,predictedoutcome)\n",
    "from naviebayes import (navie_bayes, predictedoutcome)\n",
    "from decisiontree import (decision_tree,predictedoutcome)\n",
    "from randomforest import (random_forest, predictedoutcome)\n",
    "import copy\n",
    "\n",
    "\n",
    "algorithm={ 0:random_forest,1:decision_tree,2:navie_bayes,3:k_nearest_neighbors,4:logistic_regression}\n",
    "convert={'Male':1,'Female':0,'Yes':1,'No':0, 'Positive':1, 'Negative':0}\n",
    "outputpredict={0:'Negative',1:'Positive'}\n",
    "#load a CSV file\n",
    "def load_database(filename):\n",
    "\tdataset = list()\n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tcsv_reader = reader(file)\n",
    "\t\tprint(csv_reader)\n",
    "\t\tfor row in csv_reader:\n",
    "\t\t\t\n",
    "\t\t\tif not row:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tdataset.append(row)\n",
    "\treturn dataset\n",
    "#mapping to male and femal\n",
    "def mapping(dataset):\n",
    "    for i in range(len(dataset[0])):\n",
    "        for row in dataset:\n",
    "            for i in range(len(row)):\n",
    "           \n",
    "                if convert.get(row[i])!=None:\n",
    "                    row[i]=convert[row[i]]\n",
    "                else :\n",
    "                    row[i]=float(row[i])\n",
    "                  \n",
    "\n",
    "#convert string column to float\n",
    "def convert_str_to_float(dataset):\n",
    " \n",
    "    for i in range(len(dataset[0])):\n",
    "        for row in dataset:\n",
    "            row[i]=float (row[i].strip())\n",
    "\n",
    "#calculatin mean of each column and update zero value column\n",
    "def calcuate_mean(dataset):\n",
    "    for i in range (len(dataset[0])-1):\n",
    "        sum=0.0\n",
    "        count=0\n",
    "        missingindex=[]\n",
    "        for row in dataset:\n",
    "            if row[i] != 0:\n",
    "                sum+=row[i]\n",
    "            else:\n",
    "                missingindex.append(count)   \n",
    "            count+=1\n",
    "        avg=sum/count\n",
    "    \n",
    "        for j in range(len(missingindex)):\n",
    "            dataset[missingindex[j]][i]=avg\n",
    "           \n",
    "           \n",
    "           \n",
    "#find the min and max values of each column\n",
    "def min_max_dataset(dataset):\n",
    "    minmax=list()\n",
    "    for i in range(len(dataset[0])-1):\n",
    "        col_values=[row[i] for row in dataset]\n",
    "        min_value=min(col_values)\n",
    "        max_value=max(col_values)\n",
    "        minmax.append([min_value, max_value])\n",
    "    return minmax\n",
    "# rescale dataset columns to the range to the rane 0-1\n",
    "\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i]=(row[i]-minmax[i][0])/(minmax[i][1]-minmax[i][0])\n",
    "\n",
    "#split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split=list()\n",
    "    dataset_copy=list(dataset)\n",
    "    fold_size=int(len(dataset)/n_folds)\n",
    "    fold=list()\n",
    "    fold_size=int(len(dataset)/n_folds)\n",
    "\n",
    "    while len(fold)<fold_size:\n",
    "        index=randrange(len(dataset_copy))\n",
    "        fold.append(dataset_copy.pop(index))\n",
    "      \n",
    "    return dataset_copy, fold\n",
    "\n",
    "\n",
    "#calculation of accuracy,precison,recall,f1score\n",
    "def accuracy_metric(actual, predicted):\n",
    "    truepostive=0\n",
    "    truenegative=0\n",
    "    falsepostive=0\n",
    "    falsenegative=0\n",
    " \n",
    "    for j in range(len(actual)):\n",
    "        if actual[j]==1.0:\n",
    "         \n",
    "           \n",
    "            if actual[j]==predicted[j]:\n",
    "                truepostive=truepostive+1\n",
    "            else:\n",
    "                falsepostive=falsepostive+1\n",
    "        else:\n",
    "            if actual[j]==predicted[j]:\n",
    "                truenegative=truenegative+1\n",
    "            else:\n",
    "                falsenegative=falsenegative+1\n",
    "    accuracy=(truenegative+truepostive)/(len(actual))\n",
    "    precision=(truepostive)/(truepostive+falsepostive)\n",
    "    recall=(truepostive)/(truepostive+falsenegative)\n",
    "    f1score=2*((precision*recall)/(precision+recall))\n",
    "\n",
    "    return accuracy,precision,recall,f1score\n",
    "\n",
    "output=[]\n",
    "#calling different algorithm\n",
    "def evaluate_algorithm(dataset,n_folds, user_data):\n",
    "    train_set ,test_set =cross_validation_split(dataset,n_folds)\n",
    "    accuries=list()\n",
    "    precisions=list()\n",
    "    recalls=list()\n",
    "    f1scores=list()\n",
    "    count=0\n",
    "  \n",
    "   \n",
    "    while(count<5):\n",
    "        \n",
    "        predicted=algorithm[count](train_set, test_set)\n",
    "        user_dataa=predictedoutcome(user_data)\n",
    "        output.append(outputpredict[user_dataa])\n",
    "        actual=[row[-1] for row in test_set]\n",
    "      \n",
    "       \n",
    "        if count != 0:\n",
    "            predicted=([predicted])\n",
    "        accuracy1=[]\n",
    "        precision1=[]\n",
    "        recall1=[]\n",
    "        f1score1=[]\n",
    "\n",
    "        for i in range(len(predicted)):\n",
    "            accuracy,precision,recall,f1score= accuracy_metric(actual, predicted[i])\n",
    "            accuracy1.append(accuracy)\n",
    "            precision1.append(precision)\n",
    "            recall1.append(recall)\n",
    "            f1score1.append(f1score)\n",
    "        accuries.append(accuracy1)\n",
    "        precisions.append(precision1)\n",
    "        recalls.append(recall1)\n",
    "        f1scores.append(f1score1)\n",
    "          \n",
    "           \n",
    "        \n",
    "        count+=1\n",
    "      \n",
    "        \n",
    "    return accuries,precisions,recalls,f1scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(user_data):\n",
    "    seed(1)\n",
    "    #load and prepare data\n",
    "    filename=\"/home/bikesh/Documents/6th sem/Diabetes-Prediction/Algorithms/diabetes.csv\"\n",
    "    dataset=load_database(filename)\n",
    "    #remove the header column\n",
    "    dataset.remove(dataset[0])\n",
    "    #mapping dataset with numeric value\n",
    "    mapping(dataset)\n",
    "\n",
    "    # calculate the mean\n",
    "    calcuate_mean(dataset)\n",
    "    #finding the min-max value\n",
    "    minmax=min_max_dataset(dataset)\n",
    "    #normalization the value\n",
    "    normalize_dataset(dataset, minmax)\n",
    "\n",
    "    #calculation the percentage of dataset for training data\n",
    "    n_folds = 5\n",
    "\n",
    "\n",
    "    # input here\n",
    "    mapping(user_data)\n",
    "    normalize_dataset(user_data,minmax)\n",
    "\n",
    "\n",
    "    accuries,precisions,recalls,f1scores= evaluate_algorithm(dataset,n_folds,user_data)\n",
    "    algorithmpredict={'random_forest':0,'decision-tree':1,'navie-bayes':2,'knn-algorithm':3,'logistic-regression':4}\n",
    "    # print('Scores: %s' % scores)\n",
    "    # print('random-forest','decision-tree','navie_bayes','KNN algorithm','logistic-regression')\n",
    "    # print('output: %s' % output)\n",
    "    return output\n",
    "    # print('accuries %s'% accuries)\n",
    "    # print('precisions %s'%precisions)\n",
    "    # print('recalls%s' %recalls)\n",
    "    # print('f1scores%s'%f1scores)\n",
    "    # #checking the value for random forest\n",
    "    # print('---------------------------------------------------------------------')\n",
    "    # print('randomforest%s'%output[algorithmpredict['random_forest']])\n",
    "    # print('randomforest%s'%accuries[algorithmpredict['random_forest']])\n",
    "    # print('hhhhh%s'%precisions[algorithmpredict['random_forest']])\n",
    "    # print('hhhhh%s'%recalls[algorithmpredict['random_forest']])\n",
    "    # print('hhhhh%s'%f1scores[algorithmpredict['random_forest']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<_csv.reader object at 0x7ff0d916a0b0>\n",
      "['Negative']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Negative']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "data = [['43','Male','No','No','No','Yes','No','Yes','No', 'Yes','No','No', 'Yes', 'No', 'Yes', 'No']]\n",
    "main(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(evaluate_algorithm, open(\"test.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'predict'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7b0b825b46e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test.sav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'predict'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "logistic_regression() missing 2 required positional arguments: 'train' and 'test'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7a5878819de3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: logistic_regression() missing 2 required positional arguments: 'train' and 'test'"
     ]
    }
   ],
   "source": [
    "model = logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit2b913bdcbeba4705881439cd74fcb79d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}